{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5d1836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.duplicated\n",
    "# df.drop_duplicates(inplace=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c3ae63",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb8cd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "from os.path import exists\n",
    "from collections import Counter\n",
    "from tabulate import tabulate\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "\n",
    "# Models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "# Standardisation methods\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import KernelCenterer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# Metrics methods\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Metrics methods\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac707a1",
   "metadata": {},
   "source": [
    "#### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"model_class\"   \n",
    "label_target = \"normal\" # depends on df\n",
    "label_dim1 = \"Fraud\" # depends on model logic\n",
    "label_dim2 = \"Legal\" # # depends on model logic\n",
    "label_binary1 = 0\n",
    "label_binary2 = 1\n",
    "df_headers_list = []\n",
    "column_name_time = \"time\" # depends on df\n",
    "column_name_amount = \"amount\" # depends on df\n",
    "model_train_exclusion_list = [column_name_time, column_name_amount, label]\n",
    "# seaborn\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4e0a31",
   "metadata": {},
   "source": [
    "#### Standardisation Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd40221",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling_method_standard = StandardScaler()\n",
    "scaling_method_minmax = MinMaxScaler()\n",
    "scaling_method_norm = Normalizer()\n",
    "scaling_method_kernel = KernelCenterer()\n",
    "scaling_exclusion_list = model_train_exclusion_list # depends on df and model logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6711853d",
   "metadata": {},
   "source": [
    "#### Split Train Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e52a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2\n",
    "random_state = 42\n",
    "shuffle=True\n",
    "split_train = 0.75\n",
    "split_test = 0.25\n",
    "split_validation = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5d84e7",
   "metadata": {},
   "source": [
    "#### Hyperparamaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6328c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 2\n",
    "criterion = \"entropy\"\n",
    "max_depth_dt = 4 # decision tree\n",
    "max_depth_xgb = 4 # xgb boost\n",
    "max_depth_rf = 4 # random forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60af6a0e",
   "metadata": {},
   "source": [
    "#### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e7ffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = r\"C:\\Users\\edgar\\OneDrive\\Desktop\\MSc Artificial Intelligence\\Data Science\\Unit 7 - Final Assesment\\creditcard dataset small - original.csv\" # df path\n",
    "path_df_backup = r\"C:\\Users\\edgar\\OneDrive\\Desktop\\MSc Artificial Intelligence\\Data Science\\Unit 7 - Final Assesment\\creditcard dataset small - original.csv\" # backup df path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e7f26f",
   "metadata": {},
   "source": [
    "#### Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bfba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_builder(path, backup_path):\n",
    "    file_exist_check = exists(path_df)\n",
    "    if file_exist_check == True: \n",
    "        df  = pd.read_csv(path_df)\n",
    "    else: \n",
    "        df = pd.read_csv(path_df_backup)\n",
    "    return df\n",
    "\n",
    "\n",
    "def df_lower_headers(df): \n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    return df\n",
    "\n",
    "\n",
    "def df_headers(df, df_headers_list):\n",
    "    for column in df.columns:\n",
    "        df_headers_list.append(column)\n",
    "    return df_headers_list\n",
    "\n",
    "\n",
    "def df_rename_label_header(df, label_target, label_model): \n",
    "    df.rename(columns = {label_target: label_model}, inplace = True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def df_overview(df):\n",
    "    print(\"DF Shape\")\n",
    "    print(df.shape)\n",
    "    print(\"DF Description\")\n",
    "    print(df.describe())\n",
    "\n",
    "    \n",
    "def df_scaler(df, scaling_method, scaling_exclusion_list):\n",
    "    scaling_df = df.loc[:, ~df.columns.isin(scaling_exclusion_list)]\n",
    "    scaling_df_labels = []\n",
    "    for columns in scaling_df.columns:\n",
    "        scaling_df_labels.append(columns)\n",
    "        scaling_range = scaling_df_labels\n",
    "        df[scaling_range] = scaling_method.fit_transform(df[scaling_range])\n",
    "    return df\n",
    "\n",
    "    \n",
    "def df_nan_remove(df): \n",
    "    for column in df.columns:\n",
    "        nan = df[df[column].isnull()].shape[0]\n",
    "        df = df.dropna()\n",
    "    return df\n",
    "\n",
    "\n",
    "def df_duplicates(df): # this does not work as it suppose to\n",
    "    dup = df.duplicated().any() # False\n",
    "    #dup_coordinates = df.duplicated(subset=['Student','Date']).any() # this needs to be loop to check each column with each other \n",
    "    if dup == True:\n",
    "        print(\"Duplicate Values Found\")\n",
    "    return dup\n",
    "\n",
    "\n",
    "def df_shape(df):\n",
    "    print(df.shape)\n",
    "\n",
    "    \n",
    "def df_time_conversion(df, column_name):\n",
    "    column_name = str(column_name) \n",
    "    df[column_name] = pd.to_datetime(df[column_name], unit='s')\n",
    "    df[column_name] = df[column_name].dt.strftime(\"%H:%M:%S\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def df_replace_column_header(df, current_header, new_header):\n",
    "    current_header = str(current_header)\n",
    "    new_header = str(new_header)\n",
    "    df.rename(columns={current_header:new_header}, inplace=True, axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def df_replace_column_header(df, current_header, new_header): # not sure if needed but lets it shine\n",
    "    current_header = str(current_header)\n",
    "    new_header = str(new_header)\n",
    "    df.rename(columns={current_header:new_header}, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def df_correlation_matrix(df): \n",
    "    corrmat = df.corr()\n",
    "    fig = plt.figure(figsize=(12, 9))\n",
    "    sns.heatmap(corrmat, vmax=.8, square=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94abf251",
   "metadata": {},
   "source": [
    "#### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857a6f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_binary_class(df, label_dim1, label_dim2):\n",
    "    label_dim1 = df[df[label] == class_binary2]\n",
    "    label_dim2 = df[df[label] == class_binary1]\n",
    "    return df\n",
    "\n",
    "\n",
    "def model_train_test_split(df, X_df, y_label, test_size, random_state, shuffle):\n",
    "    X = df.loc[:, ~df.columns.isin(X1_df)]\n",
    "    y = df[y1_label]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, shuffle=shuffle)\n",
    "    return (X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "def model_decision_tree(X_train, y_train):\n",
    "    tree_model = DecisionTreeClassifier(max_depth = max_depth_dt, criterion=criterion)\n",
    "    tree_model.fit(X_train, y_train)\n",
    "    tree_yhat = tree_model.predict(X_test)\n",
    "    \n",
    "    \n",
    "def model_label_definitions(label, label_target, label_dim1, label_dim2, label_binary1, label_binary2):\n",
    "    print(\"Class\")\n",
    "    print(label)\n",
    "    print(\"Originial Class Name\")\n",
    "    print(label_target)\n",
    "    print(\"Class 1 Binary Name\")\n",
    "    print(label_dim1)\n",
    "    print(\"Class 2 Binary Name\")\n",
    "    print(label_dim2)\n",
    "    print(\"Class 1 Binary Unique Identifier\")\n",
    "    print(label_binary1)\n",
    "    print(\"Class 2 Binary Unique Identifier\")\n",
    "    print(label_binary2)\n",
    "    \n",
    "    \n",
    "def model_class_balance_check_text(df, model_label, label_dim1, label_dim2): \n",
    "    count_binary1 = len(df[df.model_class == label_binary1])\n",
    "    count_binary2 = len(df[df.model_class == label_binary2])\n",
    "    count_total = len(df)\n",
    "    balance_precentage = round(count_binary1/count_binary2, 2)\n",
    "    print(\"----------------Class Balance Check----------------\")\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"Number of Fraud Cases Are: {}\".format(count_binary1))\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"Number of Legal Cases Are: {}\".format(count_binary2))\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"Number of Total Cases Are: {}\".format(count_total))\n",
    "    print(\"----------------------------------------------------\")\n",
    "    print(\"Class Balance Precentage Is: {}\".format(balance_precentage))\n",
    "    \n",
    "    \n",
    "def model_class_balance_check_charts(df):\n",
    "    pie_data = df[\" \"] = np.where(df[label] == 0,  label_dim1, label_dim2)\n",
    "    pie_data = df[\" \"].value_counts().plot(kind=\"pie\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40038ed6",
   "metadata": {},
   "source": [
    "#### DataFrame Workings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabaa827",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_builder(path_df, path_df_backup) # create df\n",
    "df = df_lower_headers(df) # lower df headers/ run as 2nd function as entire platform is based on lower headers\n",
    "df = df_rename_label_header(df, label_target, label) # change model_label name\n",
    "df = df_nan_remove(df) # remove NaN values\n",
    "df = df_time_conversion(df, column_name_time) # time column formating\n",
    "df = df_scaler(df, scaling_method_minmax, scaling_exclusion_list) # scaling algortihm \n",
    "model_class_balance_check_text(df, label, label_dim1, label_dim2)\n",
    "#model_label_definitions(label, label_target, label_dim1, label_dim2, label_binary1, label_binary2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed614f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unbalanced check\n",
    "# build pie, bar charts\n",
    "# buil table\n",
    "# unbalanced solution SMOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e1afc",
   "metadata": {},
   "source": [
    "#### Models Workings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe52aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train_test_split(df, X1_df=scaling_exclusion_list, y1_label=label, test_size=test_size, random_state=random_state, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e156ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(X_train, y_train)\n",
    "model.intercept_\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c3f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_build(model): # AEI # Artificial Edgar intelgince  \n",
    "    model = model\n",
    "    #predict = model(X_test)\n",
    "    model_intercept = model.intercept_\n",
    "    model_coefficient = model.coef_\n",
    "    return (model, model_intercept, model_coefficient)\n",
    "\n",
    "\n",
    "model_build(model=LinearRegression().fit(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7526d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop down menu\n",
    "\n",
    "root = Tk()\n",
    "root.title(\"Model Options\")\n",
    "root.geometry(\"200x200\")\n",
    "clicked = StringVar()\n",
    "first_model = clicked.set()\n",
    "drop = OptionMenu(root, clicked, \"Monday\", \"Gay\", \"Be Gay\", \"Why are you gay\")\n",
    "drop.pack()\n",
    "\n",
    "root.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819f6e26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a936ef53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e60c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be072b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3636696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb39857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1615d321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e613c706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb63bfed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeeabd86",
   "metadata": {},
   "source": [
    "#### Graveyard of Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd3ee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "knn = KNeighborsClassifier(n_neighbors = n)\n",
    "knn.fit(X_train, y_train)\n",
    "knn_yhat = knn.predict(X_test)\n",
    "\n",
    "\n",
    "#model_df_split(df)\n",
    "df = df_builder(path_df, path_df_backup)\n",
    "X = df.loc[:, df.columns != label] # needs control\n",
    "y = label\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dad27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 2, figsize=(18,4), sharex = True)\n",
    "\n",
    "amount_value = df[column_name_amount].values # values\n",
    "time_value = df[column_name_time].values # values\n",
    "\n",
    "sns.distplot(amount_value, hist=False, color=\"m\", kde_kws={\"shade\": True}, ax=axes[0]).set_title('Distribution of Amount')\n",
    "sns.distplot(time_value, hist=False, color=\"m\", kde_kws={\"shade\": True}, ax=axes[1]).set_title('Distribution of Time')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35146483",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[\"Mavs\", 0.947257], \n",
    "        [\"Suns\", 0.947257], \n",
    "        [\"Spurs\", 0.947257], \n",
    "        [\"Nets\", 0.947257]]\n",
    "          # rows\n",
    "#define header names\n",
    "col_names = [\"Team\", \"Points\"] # headers\n",
    "  \n",
    "#display table\n",
    "print(tabulate(data, headers=col_names, tablefmt=\"fancy_grid\"))\n",
    "\n",
    "\n",
    "# this is a solution but no idea how to automate it\n",
    "test1 = df[\"v1\"]\n",
    "test2 = df[\"v2\"]\n",
    "\n",
    "data = [[test1], [test2]]\n",
    "\n",
    "col_names = [\"date\", \"gay\"]\n",
    "\n",
    "\n",
    "\n",
    "# loop each row in column and show it as table??????????????????????????\n",
    "print(tabulate(data, headers=col_names, tablefmt=\"fancy_grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34bc708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# does this fixed dup column issue? \n",
    "# df.duplicated\n",
    "# df.drop_duplicates(inplace=true) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
