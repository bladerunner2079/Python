{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c926c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, boto3\n",
    "from io import StringIO\n",
    "#import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.optimize as sco\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d10580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(a, window):\n",
    "    '''\n",
    "    Use Numpy's stride tricks to create a rolling window over array a\n",
    "    Args:\n",
    "        a (ndarray): Numpy array of values to calculate rolling window over\n",
    "        window (int): Width of window\n",
    "    Returns:\n",
    "        ndarray: Array of rolling values\n",
    "    '''\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)\n",
    "\n",
    "def get_pd_dataframe(key, bucket='p-def'):\n",
    "    '''\n",
    "    Loads CSV file of data for a single company from the file key specified.\n",
    "    Args:\n",
    "        key (str): Key pointing to file in S3\n",
    "    Returns:\n",
    "        dict: Map of column name to numpy array column index\n",
    "        ndarray: Numpy array of data\n",
    "    '''\n",
    "    # Create S3 client and retrieve data based on key\n",
    "    client = boto3.client('s3')\n",
    "    obj = client.get_object(Bucket=bucket, Key=key)\n",
    "\n",
    "    # Read in data\n",
    "    raw_data = StringIO.StringIO(obj['Body'].read())\n",
    "\n",
    "    return pd.read_csv(raw_data, index_col=0, parse_dates=True)\n",
    "\n",
    "def get_data(key, bucket='p-def'):\n",
    "    '''\n",
    "    Loads CSV file of data for a single company from the file key specified.\n",
    "    Args:\n",
    "        key (str): Key pointing to file in S3\n",
    "    Returns:\n",
    "        dict: Map of column name to numpy array column index\n",
    "        ndarray: Numpy array of data\n",
    "    '''\n",
    "    # Create S3 client and retrieve data based on key\n",
    "    client = boto3.client('s3')\n",
    "    obj = client.get_object(Bucket=bucket, Key=key)\n",
    "\n",
    "    # Read in data\n",
    "    raw_data = obj['Body'].read().splitlines()\n",
    "\n",
    "    # Create map of column name to index, assuming the first column is dropped\n",
    "    header_map = {key:value-1 for value,key in enumerate(raw_data[0].split(','))}\n",
    "\n",
    "    # Discard header row and split off first column (Date column)\n",
    "    dates = [row.split(',')[0] for row in raw_data[1:]]\n",
    "    data = [\",\".join(row.split(',')[1:]) for row in raw_data[1:]]\n",
    "\n",
    "    # Creat numpy array of data\n",
    "    data = np.genfromtxt(data, delimiter=',')\n",
    "\n",
    "    return header_map, dates, data\n",
    "\n",
    "def save_data(data, key, bucket='p-def'):\n",
    "    '''\n",
    "    Writes data for a single company to a file at the specified key.\n",
    "    Args:\n",
    "        data (File buffer): File buffer containing data to write to file\n",
    "        key (str): Key pointing to file in S3\n",
    "    Returns:\n",
    "        bool: True if data was successfully written to S3\n",
    "    '''\n",
    "    #\n",
    "    s3 = boto3.resource('s3')\n",
    "    res = s3.Object(bucket, key).put(Body=data)\n",
    "\n",
    "    return res\n",
    "\n",
    "def merge_data_to_csv(header_map, dates, corp_data, results):\n",
    "    '''\n",
    "    Combines arguments back into a single CSV file.\n",
    "    Args:\n",
    "        header_map (dict): Map of column name to numpy array column index\n",
    "        dates (list): Date of each observation in the dataset\n",
    "        corp_data (ndarray): Numpy array of company data\n",
    "        results (ndarray): Numpy array of same length as company data containing asset value results\n",
    "    Returns:\n",
    "        StringIO: File buffer containined data in CSV format\n",
    "    '''\n",
    "    csv_file = StringIO.StringIO()\n",
    "\n",
    "    # Convert header map to map of index to name\n",
    "    i_to_name = {value+1:key for key, value in header_map.items()}\n",
    "\n",
    "    # Add column names for new asset value columns\n",
    "    i_start = max(i_to_name.keys()) + 1\n",
    "    for i in range(results.shape[1]):\n",
    "        i_to_name[i_start + i] = 'Va_{:d}'.format(i+1)\n",
    "\n",
    "    # Create header row\n",
    "    csv_file.write(','.join([i_to_name[i] for i in range(len(i_to_name))]) + '\\n')\n",
    "\n",
    "    # Combine company data and results and write to CSV\n",
    "    np.savetxt(csv_file, np.hstack((np.array((dates)).reshape((-1,1)), corp_data, results)), fmt='%s', delimiter=',')\n",
    "\n",
    "    # Reset file position\n",
    "    csv_file.seek(0)\n",
    "\n",
    "    return csv_file\n",
    "\n",
    "\n",
    "def solve_for_asset_value(corp_data, header_map, time_horizon, min_hist_vals=252):\n",
    "    '''\n",
    "    Solves for a firm's asset value based on a time history of the firm's equity\n",
    "    value, debt level, and risk-free rate.\n",
    "    Args:\n",
    "        corp_data (ndarray): Numpy array of company data (Equity value, face value of debt, and risk-free rate)\n",
    "        header_map (dict): Map of column name to the data column index in corp_data\n",
    "        time_horizon (list): List of time horizons (In years) to calulate asset value for\n",
    "        min_hist_vals (int): Minimum number of days to use for calculating historical data\n",
    "    Returns:\n",
    "        ndarray: Numpy array of time-series of asset values\n",
    "    '''\n",
    "    import scipy.optimize as sco\n",
    "    from scipy.stats import norm\n",
    "\n",
    "    def equations(v_a, debug=False):\n",
    "        d1 = (np.log(v_a/face_val_debt) + (r_f + 0.5*sigma_a**2)*T)/(sigma_a*np.sqrt(T))\n",
    "        d2 = d1 - sigma_a*np.sqrt(T)\n",
    "\n",
    "        y1 = v_e - (v_a*norm.cdf(d1) - np.exp(-r_f*T)*face_val_debt*norm.cdf(d2))\n",
    "\n",
    "        if debug:\n",
    "            print(\"d1 = {:.6f}\".format(d1))\n",
    "            print(\"d2 = {:.6f}\".format(d2))\n",
    "            print(\"Error = {:.6f}\".format(y1))\n",
    "\n",
    "        return y1\n",
    "\n",
    "    # Set window width for calculating historical data\n",
    "    win = 252\n",
    "\n",
    "    # Set start point of historical data\n",
    "    start_time = min_hist_vals\n",
    "    timesteps = range(min_hist_vals, len(corp_data))\n",
    "\n",
    "    # Calculate historical volatility\n",
    "    ret_col = header_map['RET']\n",
    "    sigma_e = np.zeros((corp_data.shape[0]))\n",
    "    sigma_e[:win-1] = np.nan\n",
    "    sigma_e[win-1:] = np.std(rolling_window(np.log(corp_data[:,ret_col] + 1), win), axis=-1)\n",
    "\n",
    "    assert type(time_horizon) in [list, tuple],\"time_horizon must be a list\"\n",
    "\n",
    "    # Create array for storing results\n",
    "    results = np.empty((corp_data.shape[0],len(time_horizon)))\n",
    "\n",
    "    for i, years in enumerate(time_horizon):\n",
    "        T = 252*years\n",
    "        # Set initial guess for firm value equal to the equity value\n",
    "        results[:,i] = corp_data[:,header_map['mkt_val']]\n",
    "\n",
    "        # Run through all days\n",
    "        for i_t, t in enumerate(timesteps):\n",
    "            # Check if the company is levered\n",
    "            if corp_data[t,header_map['face_value_debt']] > 1e-10:\n",
    "                # Company is levered, calculate probability of default\n",
    "                # Calculate initial guess at sigma_a\n",
    "                v_a_per = results[t-252:t,i]\n",
    "                v_a_ret = np.log(v_a_per/np.roll(v_a_per,1))\n",
    "                v_a_ret[0] = np.nan\n",
    "                sigma_a = np.nanstd(v_a_ret)\n",
    "\n",
    "                if i_t == 0:\n",
    "                    subset_timesteps = range(t-252, t+1)\n",
    "                else:\n",
    "                    #subset_timesteps = corp_data.loc[t-pd.Timedelta(20,'D'):t].index\n",
    "                    subset_timesteps = [t]\n",
    "\n",
    "                # Iterate on previous values of V_a\n",
    "                n_its = 0\n",
    "                while n_its < 10:\n",
    "                    n_its += 1\n",
    "                    # Loop over timesteps, calculating Va using initial guess for sigma_a\n",
    "                    for t_sub in subset_timesteps:\n",
    "                        r_f = (1 + corp_data[t_sub,header_map['DGS1']])**(1.0/365) - 1\n",
    "                        v_e = corp_data[t_sub,header_map['mkt_val']]\n",
    "                        face_val_debt = corp_data[t_sub,header_map['face_value_debt']]\n",
    "                        sol = sco.root(equations, results[t_sub,i])\n",
    "                        results[t_sub,i] = sol['x'][0]\n",
    "\n",
    "                    # Update sigma_a based on new values of Va\n",
    "                    last_sigma_a = sigma_a\n",
    "                    v_a_per = results[t-252:t,i]\n",
    "                    v_a_ret = np.log(v_a_per/np.roll(v_a_per,1))\n",
    "                    v_a_ret[0] = np.nan\n",
    "                    sigma_a = np.nanstd(v_a_ret)\n",
    "\n",
    "                    if abs(last_sigma_a - sigma_a) < 1e-3:\n",
    "                        #corp_data.loc[t_sub, 'sigma_a'] = sigma_a\n",
    "                        break\n",
    "            else:\n",
    "                # Company is unlevered, Va = Ve\n",
    "                pass\n",
    "\n",
    "    return results\n",
    "\n",
    "def run_model(key, time_horizon=[1,2,3,4,5]):\n",
    "    '''\n",
    "    Apply B-S option pricing model to calculate inferred firm asset values as a\n",
    "    function of time.\n",
    "    Args:\n",
    "        key (str): key pointing to data in S3\n",
    "        time_horizon (list): List of time horizons (In Years) to calculate model over\n",
    "    Returns:\n",
    "        float: Time run was started (In unix time)\n",
    "        float: Time run finished (In unix time)\n",
    "        dict: Response from S3 write\n",
    "    '''\n",
    "    start = time.time()\n",
    "\n",
    "    # Get data from S3\n",
    "    h_map, dates, data = get_data(key)\n",
    "\n",
    "    if len(dates) > 252:\n",
    "        # Run the simulation\n",
    "        results = solve_for_asset_value(data, h_map, time_horizon=time_horizon)\n",
    "\n",
    "        # Merge data back into CSV\n",
    "        csv_file = merge_data_to_csv(h_map, dates, data, results)\n",
    "\n",
    "        # Save results to S3\n",
    "        result_key = key.replace('merged-corp-data', 'merton-results')\n",
    "        response = save_data(csv_file, result_key)\n",
    "    else:\n",
    "        response = False\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    return start, end, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ca9016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf40971f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
